{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbd1bef6",
   "metadata": {},
   "source": [
    "1. The advantages of a CNN over a fully connected DNN for image classification are:\n",
    "- CNNs are designed to handle spatial information in images, while fully connected DNNs treat input features as independent, which can lead to a high number of parameters and overfitting.\n",
    "- CNNs use shared weights, meaning that the same weights are applied to different parts of the image, which reduces the number of parameters and allows the network to learn translation invariance.\n",
    "- CNNs can use pooling layers to downsample the feature maps, reducing the number of parameters and preventing overfitting.\n",
    "\n",
    "2. The total number of parameters in the CNN is:\n",
    "- First convolutional layer: (3*3*3)*100 = 2,700\n",
    "- Second convolutional layer: (3*3*100)*200 = 1,800,000\n",
    "- Third convolutional layer: (3*3*200)*400 = 7,200,000\n",
    "- Fully connected layer: (400*10) = 4,000\n",
    "Total number of parameters: 8,006,700\n",
    "If we are using 32-bit floats, the network will require approximately 30.8 MB of RAM when making a prediction for a single instance, and approximately 1.54 GB of RAM when training on a mini-batch of 50 images.\n",
    "\n",
    "3. Five things you could try to solve the problem of GPU running out of memory while training a CNN are:\n",
    "- Reduce the batch size.\n",
    "- Use a smaller model.\n",
    "- Use a model with fewer layers.\n",
    "- Use smaller images.\n",
    "- Use mixed precision training.\n",
    "\n",
    "4. Max pooling layers reduce the spatial dimensions of the feature maps while retaining the most important information, which helps to prevent overfitting and reduce the number of parameters. A convolutional layer with the same stride would not necessarily have this effect.\n",
    "\n",
    "5. Local response normalization layers are used to increase the generalization of the network by normalizing the activity of the neurons in a local neighborhood. This can help to prevent overfitting and improve the accuracy of the network.\n",
    "\n",
    "6. AlexNet introduced several innovations compared to LeNet-5, including:\n",
    "- The use of ReLU activation functions instead of sigmoid functions.\n",
    "- The use of dropout regularization to prevent overfitting.\n",
    "- The use of data augmentation to increase the size of the training set.\n",
    "- The use of GPU acceleration to speed up training.\n",
    "GoogLeNet introduced several innovations, including:\n",
    "- The use of inception modules, which concatenate feature maps from multiple different-sized filters.\n",
    "- The use of global average pooling, which reduces the number of parameters and prevents overfitting.\n",
    "- The use of auxiliary classifiers, which provide additional supervision and help to prevent vanishing gradients.\n",
    "ResNet introduced residual connections, which allow for deeper networks to be trained without vanishing gradients.\n",
    "SENet introduced squeeze-and-excitation modules, which adaptively recalibrate the channel-wise feature responses.\n",
    "Xception introduced depthwise separable convolutions, which separate the spatial and channel-wise convolutions.\n",
    "\n",
    "7. A fully convolutional network is a network that replaces the fully connected layers of a traditional network with convolutional layers, allowing it to take input of arbitrary size and output feature maps of the same size. To convert a dense layer into a convolutional layer, the weights of the dense layer can be reshaped into a 1x1 convolutional layer, and the input to the dense layer can be reshaped into a feature map.\n",
    "\n",
    "8. The main technical difficulty of semantic segmentation is to produce accurate and detailed segmentations of objects in an image, while maintaining spatial coherence and handling variations in object shape, size, and occlusion. This requires the use of complex architectures and training techniques, as well as careful preprocessing and postprocessing of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d813f4ee",
   "metadata": {},
   "source": [
    "9.Here's an example CNN architecture that you can build from scratch to achieve high accuracy on the MNIST dataset:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aee4c526",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# assuming you have already loaded and preprocessed the MNIST dataset\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d575b854",
   "metadata": {},
   "source": [
    "10.Here are the steps for using transfer learning for large image classification:\n",
    "a. Create a training set containing at least 100 images per class. For example, you could download the \"flower_photos\" dataset from TensorFlow Datasets, which contains images of flowers categorized into five classes: daisy, dandelion, roses, sunflowers, and tulips.\n",
    "\n",
    "b. Split the dataset into a training set, a validation set, and a test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset, info = tfds.load('flower_photos', with_info=True, as_supervised=True)\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "validation_split = 0.2\n",
    "num_examples = info.splits['train'].num_examples\n",
    "num_valid_examples = int(validation_split * num_examples)\n",
    "\n",
    "train_dataset = train_dataset.skip(num_valid_examples)\n",
    "validation_dataset = train_dataset.take(num_valid_examples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5edfe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255.0\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_image).shuffle(1000).batch(32)\n",
    "validation_dataset = validation_dataset.map(preprocess_image).batch(32)\n",
    "test_dataset = test_dataset.map(preprocess_image).batch(32)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf77a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet50(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    data_augmentation,\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=10,\n",
    "                    validation_data=validation_dataset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
